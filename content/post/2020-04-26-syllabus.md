---
title: Syllabus
author: Christopher Gandrud
date: '2021-03-15'
slug: syllabus
weight: 1
categories:
  - admin
tags:
  - admin
Categories: []
Description: ''
Tags: []
---

# \[Core Methods: Data Science\] Programming Methods for Data Retrieval & Management

**Instructor: Christopher Gandrud, PhD**

**Email:** [christopher.gandrud\@gmail.com](mailto:christopher.gandrud@gmail.com)

**Class:** **TO UPDATE**

**Location:** Virtual

## üìú Course Description

**Part I:** Introduction to programming and statistical simulation

Social scientists increasingly rely on computational methods and tools to help understand social phenomena. Computational tools are crucial for making sense of large new social data sets and computational thinking can aid scientists in modelling social processes. In this hands on workshop, we will learn the key components of programming in R and statistical simulation. We will learn how to explore social processes by (1) creating abstract social models in R, (2) simulating their dynamics, and (3) visualising the outcomes. In the process, you will learn about R's data structures, how to write functions, how to efficiently execute functions using computation, debugging, and how to visualise data using ggplot2.

These skills will be directly useful for the follow up workshop on programming methods for automated data retrieval and management.

**Part II:** Data Retrieval & Management

The rapid growth of the World Wide Web over the past two decades tremendously changed the way in which we share, collect and publish data. The web is full of data that are of great interest to scientists and businesses alike. Firms, public institutions and private users provide every imaginable type of information and new channels of communication generate vast amounts of data on human behaviour. But how to efficiently collect data from the internet, retrieve information from social networks, search engines and dynamic web pages, tap web services and finally, process and manage the large volume of collected data with statistical software? What was once a fundamental problem for the social sciences - the scarcity and inaccessibility of observations - is quickly turning into an abundance of data. The internet offers non-reactive measurements of behaviour and preferences of political and other actors (for example, citizens, representatives, courts, and media).

The aim of the course is to provide the **technical bases** for **web data collection methods** and subsequent **data management**. Furthermore, we will study state-of-the art applications from the social sciences that exploit the potential of web-based data to tackle both classical and new questions of social science. This course will provide an introduction to the basics of web data collection practice with **R**. The sessions are **hands-on**; participants will **practice every step of the process with R** using various examples. The doctoral candidates will learn how to scrape content from **static** and **dynamic** web pages, **connect to APIs** from popular web services, to read out and process user data and to set up automatically working scraper programs. For the practical part, the course participants are expected to independently design and collect data for their own empirical applications.

## üóù Enrollment

**Prerequisite(s):** Some experience with statistical programming languages such as Stata, R, or Python.

## Format

The course will take place over four days. Two Fridays and two Saturdays. Fridays will be full day lectures. The Saturdays will be half days (mornings) dedicated to applying what you've learned in the lectures in group exercises.

We'll break the course into **1.5 hour blocks**. Each block ends with a 15 minute break/time to ask 1:1 questions. The first 5 blocks cover Part I of the course. They are optional, but highly recommended. Especially from the afternoon of the first day, we will cover more advanced topics of statistical simulation and distributed computing.

All of the blocks include interactive time where you can use the material presented in the block in a semi-structured exercise with a partner.

Each day, we'll take 1 hour for lunch. At the end of Day 1 we'll catch up with a **retro** using the 4 L's format (Like, Learned, Lacked, Longed For). Hopefully this will help us identify areas of improvement for the second day.

## Course topic overview and timeline

The course timeline is available [here](https://www.notion.so/fcbe957300b7491da31519496ce2591c?v=1dabef0c5ec74aaa8fd7a57f0afa53b9).

# Collaboration tools

**Integrated Developer Environment:** [RStudio Cloud](https://rstudio.cloud/project/1140732)

**Video:** [Zoom Room](https://hu-berlin.zoom.us/j/95438130830?pwd=VzBoK283VmRRYU1WTkV2UTYrK25lUT09). Password: \[TO UPDATE\]. Meeting ID: \[TO UPDATE\].

**Chat:** Zoom

**Retro Board**: [Miro board invite link](https://miro.com/welcomeonboard/FM4bLP7VzR2pqQTVn2rZBySYZvvas5dFnqkvu06PThVfCb3HYV6qmKlM5tdfJPDu)

## üìñ Recommended Readings

-   [Automated Data Collection with R: A practical guide to web scraping and text mining](https://onlinelibrary.wiley.com/doi/book/10.1002/9781118834732)

-   [Reproducible Research with R and RStudio (3rd Edition)](https://brave-pasteur-c09ffa.netlify.app/slides/code/bookdown.pdf)

-   [Guide on Good Data Protection Practice in Research](https://www.eui.eu/Documents/ServicesAdmin/DeanOfStudies/ResearchEthics/Guide-Data-Protection-Research.pdf)

-   [Twitter: Products for Researchers](https://developer.twitter.com/en/use-cases/academic-researchers/products-for-researchers)

-   [RStudio Primers](https://rstudio.cloud/learn/primers)

## üôÄ Live coding examples

Most of the rough and tumble live coding examples are available [here](https://github.com/christophergandrud/hu-live-coding-course-examples).
