	
	<!doctype html>
<html lang="en">
  <head>
    <title> - Syllabus</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">

    
    <link href="/css/milk.min.css" rel="stylesheet">
    <link href="/css/milk-responsive.min.css" rel="stylesheet">     
    <link href="/css/style.css" rel="stylesheet" type="text/css" media="all">
    <link href="/css/fonts.css" rel="stylesheet" type="text/css" media="all">
    <link rel="shortcut icon" href="/images/chart-icon.ico">
    <link rel="apple-touch-icon" href="">
    <link rel="canonical" href="/post/syllabus/">

    
    <link href="/rss.xml" type="application/atom+xml" rel="alternate" title="Programming Methods for Data Retrieval &amp; Management">

  </head>
  <body>
    <div class="navbar navbar-fixed-top">
  <div id="navbar-inner">
    <div id="logo">
       <a href="https://brave-pasteur-c09ffa.netlify.app/"><img src="/images/cover-img.png" width="1000px"></img></a>
    </div>
  </div>
</div>


<div class="container">
  <div class="content">
    <div class="row-fluid">
      <div class="span12">
        <div class="posts">


	    
	  <div class="post">
	    <header class="post-header">
	        <h1><a href="/post/syllabus/">Syllabus</a></h1>
	        <div class="post-time">April 26 2020</div>
	    </header>
	    <div class="post-after">
	        <div class="tags">
	            
	        </div>
	    </div>
	    <hr>
	    <div class="post content">
	        <h1 id="core-methods-data-science-programming-methods-for-data-retrieval--management">[Core Methods: Data Science] Programming Methods for Data Retrieval &amp; Management</h1>
<p><strong>Instructor: Christopher Gandrud, PhD</strong></p>
<p><strong>Email:</strong> <a href="mailto:christopher.gandrud@gmail.com">christopher.gandrud@gmail.com</a></p>
<p><strong>Class:</strong> 9.00-17.00, 12-13 June 2020</p>
<p><strong>Location:</strong> Virtual</p>
<h1 id="-course-description">üìú Course Description</h1>
<p>The rapid growth of the World Wide Web over the past two decades tremendously changed the way in which we share, collect and publish data. The web is full of data that are of great interest to scientists and businesses alike. Firms, public institutions and private users provide every imaginable type of information and new channels of communication generate vast amounts of data on human behaviour. But how to efficiently collect data from the internet, retrieve information from social networks, search engines and dynamic web pages, tap web services and finally, process and manage the large volume of collected data with statistical software? What was once a fundamental problem for the social sciences - the scarcity and inaccessibility of observations - is quickly turning into an abundance of data. The internet offers non-reactive measurements of behaviour and preferences of political and other actors (for example, citizens, representatives, courts, and media).</p>
<p>The aim of the course is to provide the <strong>technical bases</strong> for <strong>web data collection methods</strong> and subsequent <strong>data management</strong>. Furthermore, we will study state-of-the art applications from the social sciences that exploit the potential of web-based data to tackle both classical and new questions of social science. This course will provide an introduction to the basics of web data collection practice with <strong>R</strong>. The sessions are <strong>hands- on</strong>; participants will <strong>practice every step of the process with R</strong> using various examples. The doctoral candidates will learn how to scrape content from <strong>static</strong> and <strong>dynamic</strong> web pages, <strong>connect to APIs</strong> from popular web services such as Twitter, to read out and process user data and to set up automatically working scraper programs. For the practical part, the course participants are expected to independently design and collect data for own empirical applications.</p>
<h1 id="-enrollment">üóù Enrollment</h1>
<p><strong>Prerequisite(s):</strong> Some experience with statistical programming languages such as Stata or R</p>
<h1 id="format">Format</h1>
<p>This is my first time running this course remotely. So let&rsquo;s experiment.</p>
<p>To start, let&rsquo;s break the course into <strong>four 1.5 hour blocks</strong>. Each block ends with a 15 minute break/time to ask 1:1 questions. The first two blocks cover R Basics (e.g. setting up R and RStudio, objects, assignment, loops). These blocks are optional but highly recommended unless you have strong R experience.</p>
<p>Each day, we&rsquo;ll take 1 hour for lunch. At the end of Day 1 we&rsquo;ll catch up with a <strong>retro</strong> using the 4 L&rsquo;s format (Like, Learned, Lacked, Longed For).</p>
<p>The last block will be a pair project. With a partner, you&rsquo;ll identify a web-based data source and create a plan to scrape the data and transform it.</p>
<p><a href="https://miro.com/app/board/o9J_kuc1TmQ=/">https://miro.com/app/board/o9J_kuc1TmQ=/</a></p>
<h1 id="collaboration-tools">Collaboration tools</h1>
<p><strong>Integrated Developer Environment:</strong> <a href="https://rstudio.cloud/project/1140732">RStudio Cloud</a></p>
<p><strong>Video:</strong></p>
<p><strong>Chat:</strong></p>
<h1 id="-recommended-readings">üìñ Recommended Readings</h1>
<ul>
<li>
<p><a href="https://onlinelibrary.wiley.com/doi/book/10.1002/9781118834732">Automated Data Collection with R: A practical guide to web scraping and text mining</a></p>
</li>
<li>
<p>Reproducible Research with R and RStudio (3rd Edition)</p>
</li>
<li>
<p><a href="https://www.eui.eu/Documents/ServicesAdmin/DeanOfStudies/ResearchEthics/Guide-Data-Protection-Research.pdf">Guide on Good Data Protection Practice in Research</a></p>
</li>
<li>
<p><a href="https://developer.twitter.com/en/use-cases/academic-researchers/products-for-researchers">Twitter: Products for Researchers</a></p>
</li>
<li>
<p><a href="https://rstudio.cloud/learn/primers">RStudio Primers</a></p>
</li>
</ul>

	    </div>
	    
	<div class="about">
	<p> 
     
    </p>
</div>
		<nav id="pagination">
			
			<a class="next" href="/post/why-automated-data-collection/">Next</a>
		</nav>
	
		        <footer>
		        	Built with <a href="https://github.com/spf13/hugo">Hugo</a> using <a href="https://themes.gohugo.io/theme/simple-a/">simple-a</a>
		        	<p>Christopher Gandrud 2020</p>
		        </footer>
		    </div>
		  </div>
		</div>
      </div>
    </div>
</body>

<script type="text/javascript">
  var _paq = _paq || [];
  _paq.push(['trackPageView']);
  _paq.push(['enableLinkTracking']);
  (function() {
    var u=(("https:" == document.location.protocol) ? "https" : "http") + ":change-me";
    _paq.push(['setTrackerUrl', u+'piwik.php']);
    _paq.push(['setSiteId', 4]);
    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0]; g.type='text/javascript';
    g.defer=true; g.async=true; g.src=u+'piwik.js'; s.parentNode.insertBefore(g,s);
  })();
</script>


</html>

